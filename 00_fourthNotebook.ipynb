{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOx0+I8krvweAk8iz/QyaMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewHawksbyGithub/pytorch-deep-learning/blob/main/00_fourthNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5WXUViPYzm1",
        "outputId": "950fa975-eeb2-45a3-e161-3168b65cb17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True, True],\n",
            "        [True, True, True],\n",
            "        [True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#PyTorch has functionality to interact with numPy.\n",
        "#Data may be made up of NumPy arrays, can easily be converted to pyTorch\n",
        "#tensors. torch.from_numpy(ndarray)\n",
        "#PyTorch Tensor -> NumPy -> torch.Tensor.numpy()\n",
        "\n",
        "#array = np.arange(1.0, 8.0)\n",
        "#tensor = torch.from_numpy(array)\n",
        "#array, tensor\n",
        "\n",
        "#NumPy's default datatype is float64.\n",
        "#Torch's default datatype is float32.\n",
        "\n",
        "#tensor and array in this example use different memory. A new object is created.\n",
        "\n",
        "#tensor = torch.ones(7)\n",
        "#numpy_tensor = tensor.numpy()\n",
        "#tensor, numpy_tensor\n",
        "\n",
        "#default datatype from torch is float32 and this carries over if you\n",
        "#convert it into a numpy array.\n",
        "\n",
        "#Again, This is a seperate object and they do not share memory. Changing\n",
        "#One does not change the other.\n",
        "\n",
        "#REPRODUCIBILITY\n",
        "\n",
        "#Start with random numbers. Run Tensor operations. Update the random numbers to\n",
        "#try to make them fit the data. Repeat and repeat.\n",
        "\n",
        "#To reduce randomness in neural networks and pyTorch comes the concept of a\n",
        "#random seed. The random seed 'Flavours' the randomness. The randomness in\n",
        "#pyTorch is pseudo-randomness, which is fundamentally deterministic.\n",
        "\n",
        "#random_tensor_A = torch.rand(3,4)\n",
        "#random_tensor_B = torch.rand(3,4)\n",
        "#print (random_tensor_A == random_tensor_B)\n",
        "\n",
        "#Let's make some random, but reproducible tensors.\n",
        "\n",
        "#RANDOM_SEED = 9\n",
        "#torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "#random_tensor_C = torch.rand(3,3)\n",
        "\n",
        "#torch.manual_seed(RANDOM_SEED)\n",
        "#random_tensor_D = torch.rand(3,3)\n",
        "#print(random_tensor_C == random_tensor_D) #These tensors are IDENTICAL.\n",
        "#---->PSEUDO-RANDOMNESS.\n",
        "#Call torch.manual_seed(SAME_SEED) everytime if you want reproducibility.\n",
        "#There is an entire document related to reproducibility in the docs.\n",
        "\n",
        "#RUNNING TENSORS AND PYTORCH OBJECTS ON GPUS.\n",
        "\n",
        "### 1. Getting a GPU.\n",
        "#Use google colab for a free GPU. There is also google colab pro. and pro+.\n",
        "#Options to upgrade as well; ---> using your own GPU....\n",
        "#Tim Dettmers.\n",
        "\n",
        "#Use cloud computing -> GCP, AWS, Azure.\n",
        "\n",
        "#For 2, 3 PyTorch + GPU Drivers, (CUDA) there are setup guides\n",
        "#in the PyTorch Docs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}